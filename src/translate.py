import os
import math
import torch
import torchaudio
import kss  # ë¬¸ì¥ ë‹¨ìœ„ ë¶„ë¦¬
import pyttsx3
import numpy as np
from tqdm import tqdm
from transformers import (
    WhisperProcessor, WhisperForConditionalGeneration,
    BartForConditionalGeneration, AutoTokenizer
)

# 1) ì‚¬ìš©ìì—ê²Œ ì‚¬íˆ¬ë¦¬ ì¢…ë¥˜ ì„ íƒ ë°›ê¸°
print("ì‚¬íˆ¬ë¦¬ ë²ˆì—­ê¸°ì˜ ì§€ì—­ì„ ì„ íƒí•˜ì„¸ìš”:")
print("1. ê²½ìƒë„ ì‚¬íˆ¬ë¦¬ ë²ˆì—­")
print("2. ì œì£¼ë„ ì‚¬íˆ¬ë¦¬ ë²ˆì—­")
print("3. ì „ë¼ë„ ì‚¬íˆ¬ë¦¬ ë²ˆì—­")
print("4. ê°•ì›ë„ ì‚¬íˆ¬ë¦¬ ë²ˆì—­")
choice = input("ë²ˆí˜¸ ì…ë ¥ (1 ~ 4): ").strip()
if choice == "1":
    stt_dir = r"D:\PyCharm\dialect_translator\src\stt\gsang_model"
    trans_dir = r"D:\PyCharm\dialect_translator\models\model03"
    wav_dir = r"D:\PyCharm\dialect_translator\Data\gsang_voice_data\wav1"
    print("[ê²½ìƒë„ ì‚¬íˆ¬ë¦¬ ëª¨ë¸ ë° íŒŒì¼ ê²½ë¡œ ì„¤ì •]")
elif choice == "2":
    stt_dir = r"D:\PyCharm\dialect_translator\src\stt\jeju_model"
    trans_dir = r"D:\PyCharm\dialect_translator\models\jeju"
    wav_dir = r"D:\PyCharm\dialect_translator\Data\jeju_voice_data\wav1"
    print("[ì œì£¼ë„ ì‚¬íˆ¬ë¦¬ ëª¨ë¸ ë° íŒŒì¼ ê²½ë¡œ ì„¤ì •]")
elif choice == "3":
    stt_dir = r"D:\PyCharm\dialect_translator\src\stt\jeolla_model"
    trans_dir = r"D:\PyCharm\dialect_translator\models\jeolla"
    wav_dir = r"D:\PyCharm\dialect_translator\Data\jeolla_voice_data\wav1"
    print("[ì „ë¼ë„ ì‚¬íˆ¬ë¦¬ ëª¨ë¸ ë° íŒŒì¼ ê²½ë¡œ ì„¤ì •]")
elif choice == "4":
    stt_dir = r"D:\PyCharm\dialect_translator\src\stt\gangwon_model"
    trans_dir = r"D:\PyCharm\dialect_translator\models\gangwon"
    wav_dir = r"D:\PyCharm\dialect_translator\Data\gangwon_voice_data\wav1"
    print("[ê°•ì›ë„ ì‚¬íˆ¬ë¦¬ ëª¨ë¸ ë° íŒŒì¼ ê²½ë¡œ ì„¤ì •]")
else:
    raise ValueError("ì˜ëª»ëœ ì…ë ¥ì…ë‹ˆë‹¤. 1 ~ 4 ì¤‘ ì…ë ¥í•´ì£¼ì„¸ìš”.")

# 2) ì¥ë¹„ ì„¤ì •
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"ğŸ–¥ï¸ ì‚¬ìš© ì¥ì¹˜: {device}")

# 3) STT ëª¨ë¸ & processor ë¡œë“œ
print("ğŸ“¥ STT ëª¨ë¸ ë¡œë“œ ì¤‘...")
stt_model = WhisperForConditionalGeneration.from_pretrained(stt_dir).to(device)
stt_model.config.forced_decoder_ids = None
stt_model.config.suppress_tokens = []
stt_model.generation_config.forced_decoder_ids = None
stt_model.generation_config._from_model_config = True
stt_processor = WhisperProcessor.from_pretrained(stt_dir)
stt_model.eval()

# 4) ë²ˆì—­ ëª¨ë¸ ë¡œë“œ
print("ğŸ“¥ ë²ˆì—­ ëª¨ë¸ ë¡œë“œ ì¤‘...")
trans_model = BartForConditionalGeneration.from_pretrained(trans_dir).to(device)
trans_tokenizer = AutoTokenizer.from_pretrained(trans_dir)
trans_model.eval()

# 5) pyttsx3 TTS ì—”ì§„ ì„¤ì •
print("ğŸ”Š TTS ì—”ì§„ ì„¤ì • ì¤‘...")
tts_engine = pyttsx3.init()
tts_engine.setProperty("rate", 150)


# 6) ì˜¤ë””ì˜¤ ë¶„í•  í•¨ìˆ˜ (ìˆ˜ì •ë¨)
def load_audio_chunks(path, chunk_sec=30):
    try:
        wav, sr = torchaudio.load(path)

        # ìŠ¤í…Œë ˆì˜¤ë¥¼ ëª¨ë…¸ë¡œ ë³€í™˜
        if wav.shape[0] > 1:
            wav = torch.mean(wav, dim=0, keepdim=True)

        # ë¦¬ìƒ˜í”Œë§
        if sr != 16000:
            wav = torchaudio.transforms.Resample(sr, 16000)(wav)

        # (1, N) -> (N,) í˜•íƒœë¡œ ë³€í™˜
        wav = wav.squeeze()

        size = 16000 * chunk_sec
        chunks = []

        for i in range(0, len(wav), size):
            chunk = wav[i:i + size]
            # numpy arrayë¡œ ë³€í™˜
            chunk_np = chunk.numpy() if isinstance(chunk, torch.Tensor) else chunk
            chunks.append(chunk_np)

        return chunks

    except Exception as e:
        print(f"âŒ ì˜¤ë””ì˜¤ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return []


# 7) STT + ë¬¸ì¥ ë¶„ë¦¬ (ìˆ˜ì •ë¨)
def transcribe_sentences(path):
    if not os.path.exists(path):
        print(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {path}")
        return []

    chunks = load_audio_chunks(path)
    if not chunks:
        return []

    print(f"ğŸ” ì´ {len(chunks)}ê°œ chunk ì²˜ë¦¬")
    texts = []

    for i, chunk in enumerate(chunks, 1):
        try:
            # chunkê°€ ì´ë¯¸ numpy arrayì¸ì§€ í™•ì¸
            if isinstance(chunk, torch.Tensor):
                chunk = chunk.numpy()

            # processorì— ë‹¨ì¼ ì˜¤ë””ì˜¤ë¡œ ì „ë‹¬ (ë¦¬ìŠ¤íŠ¸ë¡œ ê°ì‹¸ì§€ ì•ŠìŒ)
            inp = stt_processor(chunk, sampling_rate=16000, return_tensors="pt")
            feats = inp.input_features.to(device)

            with torch.no_grad():
                preds = stt_model.generate(
                    feats,
                    max_new_tokens=440,
                    num_beams=5,
                    early_stopping=True,
                    do_sample=False,
                    task="transcribe",
                    language="ko"
                )

            txt = stt_processor.batch_decode(preds, skip_special_tokens=True)[0]
            texts.append(txt)
            print(f"  â€¢ chunk {i}/{len(chunks)} ì™„ë£Œ: {txt[:30]}...")

        except Exception as e:
            print(f"âŒ chunk {i} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            continue

    if not texts:
        print("âŒ ìŒì„± ì¸ì‹ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return []

    # ë¬¸ì¥ ë¶„ë¦¬
    combined_text = " ".join(texts)
    sentences = kss.split_sentences(combined_text)

    # ë¹ˆ ë¬¸ì¥ ì œê±°
    return [s.strip() for s in sentences if s.strip()]


# 8) í•œ ë¬¸ì¥ì”© ë²ˆì—­
def translate_sentences(dialect_sents):
    if not dialect_sents:
        return []

    results = []
    for sent in tqdm(dialect_sents, desc="ğŸ”„ ë²ˆì—­ ì¤‘"):
        try:
            enc = trans_tokenizer(
                sent,
                return_tensors="pt",
                truncation=True,
                padding=True,
                max_length=64,
            ).to(device)

            with torch.no_grad():
                out = trans_model.generate(
                    enc.input_ids,
                    attention_mask=enc.attention_mask,
                    max_new_tokens=64,
                    eos_token_id=trans_tokenizer.eos_token_id,
                    pad_token_id=trans_tokenizer.pad_token_id,
                    num_beams=4,
                    early_stopping=True,
                )

            translated = trans_tokenizer.decode(out[0], skip_special_tokens=True)
            results.append(translated)

        except Exception as e:
            print(f"âŒ ë²ˆì—­ ì‹¤íŒ¨: {sent[:20]}... - {e}")
            results.append(sent)  # ë²ˆì—­ ì‹¤íŒ¨ì‹œ ì›ë¬¸ ìœ ì§€

    return results


# 9) ì‹¤í–‰ ë° ê²°ê³¼ ì¶œë ¥
if __name__ == "__main__":
    try:
        # wav íŒŒì¼ ì„ íƒ: ë””ë ‰í† ë¦¬ì—ì„œ ì›í•˜ëŠ” íŒŒì¼ëª…ì„ ì§€ì •í•˜ì„¸ìš”
        filename = "1.wav"  # ì˜ˆì‹œ íŒŒì¼ëª…
        wav_path = os.path.join(wav_dir, filename)

        print(f"ğŸµ ì²˜ë¦¬í•  íŒŒì¼: {wav_path}")

        # STT ì²˜ë¦¬
        print("\nğŸ™ï¸ ìŒì„± ì¸ì‹ ì‹œì‘...")
        dialect_sents = transcribe_sentences(wav_path)

        if not dialect_sents:
            print("âŒ ìŒì„± ì¸ì‹ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            exit()

        print(f"âœ… {len(dialect_sents)}ê°œ ë¬¸ì¥ ì¸ì‹ ì™„ë£Œ")

        # ë²ˆì—­ ì²˜ë¦¬
        print("\nğŸ”„ ë²ˆì—­ ì‹œì‘...")
        std_sents = translate_sentences(dialect_sents)

        # ì‚¬íˆ¬ë¦¬ì™€ í‘œì¤€ì–´ê°€ ë‹¤ë¥¸ ë¬¸ì¥ë§Œ í•„í„°ë§
        filtered = [(d, s) for d, s in zip(dialect_sents, std_sents)
                    if d.strip() != s.strip() and len(d.strip()) > 0]

        if not filtered:
            print("âŒ ë²ˆì—­í•  ì‚¬íˆ¬ë¦¬ ë¬¸ì¥ì´ ì—†ìŠµë‹ˆë‹¤.")
            exit()

        print(f"âœ… {len(filtered)}ê°œ ë¬¸ì¥ ë²ˆì—­ ì™„ë£Œ")

        # ê²°ê³¼ ì¶œë ¥
        print("\nğŸ“‹ ìµœì¢… ê²°ê³¼ (ë²ˆí˜¸ í¬í•¨):\n")
        for idx, (d, s) in enumerate(filtered, 1):
            print(f"{idx}. [ì‚¬íˆ¬ë¦¬] {d}")
            print(f"   [í‘œì¤€ì–´] {s}")
            print("-" * 50)

        # ì‚¬ìš©ì ì¸í„°ë™ì…˜
        print(f"\nğŸ”¢ ì½ì„ ë¬¸ì¥ ë²ˆí˜¸ë¥¼ ì…ë ¥í•˜ì„¸ìš” (1-{len(filtered)}, ì¢…ë£Œí•˜ë ¤ë©´ ì—”í„°ë§Œ ì…ë ¥):")
        while True:
            choice = input("ë²ˆí˜¸> ").strip()
            if not choice:
                print("í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                break

            if not choice.isdigit() or not (1 <= int(choice) <= len(filtered)):
                print(f"1ë¶€í„° {len(filtered)} ì‚¬ì´ì˜ ìˆ«ìë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                continue

            d, s = filtered[int(choice) - 1]
            print(f"\n[ì‚¬íˆ¬ë¦¬] {d}")
            print(f"[í‘œì¤€ì–´] {s}")
            print("-" * 50)

            try:
                print("ğŸ”Š ìŒì„± ì¶œë ¥ ì¤‘...")
                tts_engine.say(s)
                tts_engine.runAndWait()
            except Exception as e:
                print(f"âŒ TTS ì‹¤íŒ¨: {e}")

    except Exception as e:
        print(f"âŒ í”„ë¡œê·¸ë¨ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        print(f"ì˜¤ë¥˜ íƒ€ì…: {type(e).__name__}")
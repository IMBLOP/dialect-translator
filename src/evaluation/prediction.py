import math
import pandas as pd
import torch
from transformers import BartForConditionalGeneration, AutoTokenizer
from tqdm import tqdm

# ----------------------------
# 1) 모델 & 토크나이저 로딩
# ----------------------------
MODEL_DIR = r"C:\INHATC\dialect_translator\models\model03"  # 학습된 모델 경로
model = BartForConditionalGeneration.from_pretrained(MODEL_DIR)
tokenizer = AutoTokenizer.from_pretrained(MODEL_DIR)

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)
model.eval()

# ----------------------------
# 2) 경상도 사투리 100문장 (standard는 없음)
# ----------------------------
dialects = [
    "니 뭐하노?",
    "점심 묵었나?",
    "오늘 날씨 죽이네예.",
    "얘, 거 가면 안 됀다, 알겠나?",
    "아이고, 허리가 끊어지겠데이.",
    "그거 얼마주고 샀노?",
    "야, 빨리 온나!",
    "밥은 묵고 다니나?",
    "어데 가꼬 있노?",
    "날씨가 쌀쌀해서 죽겠다.",
    "니 시방 울라카나?",
    "와 이리 피곤하노, 잠 좀 자야겠데이.",
    "우리 집에 진짜 맛난 반찬 많데이.",
    "거기 앉아있지 말고, 좀 도와주이소.",
    "오빠, 오늘 약속 안 잊었제?",
    "오늘 장 보러 시장 갈낀데, 같이 갈래?",
    "국물 좀 더 달라캤더니, 눈치 주더라.",
    "니는 왜 이리 말이 많노?",
    "우리 집 개, 겁나 크데이.",
    "시험공부 안 하모 큰일 나지 않겠나.",
    "동네 사람들 모이면 다 술 한 잔씩 하데이.",
    "와, 이거 완전 배 터지겠데이.",
    "내 오늘 일찍 퇴근해야 된데이.",
    "지가 아무리 잘났다고 해도, 그건 아니데이.",
    "저 아저씨, 뭔 일이라카노?",
    "니, 용돈 받아쓰나?",
    "형, 또 잔다 아이가!",
    "눈 오니까 길 미끄럽데이. 조심해라.",
    "그거, 내가 하란 말이고!",
    "야, 니 내일 뭐 하노?",
    "솔직히 좀 겁난다, 안 그렇나?",
    "와, 가게에 손님이 줄지어 서 있데이.",
    "할매가 손주 오매 기다린다카더라.",
    "머리 좀 깎아야겠다, 지저분하데이.",
    "이때까지 뭐하고 있었노, 연락도 없고.",
    "니가 더 잘 알겠지, 안 그라나?",
    "에이, 귀찮아 죽겠네예.",
    "우리 집 강아지, 이름이 뭔 줄 아나?",
    "이 차, 엄청 빠르데이.",
    "잔소리는 그만해라, 듣기 싫데이.",
    "이번에 새로 생긴 식당, 맛있다카더라.",
    "카페 가볼라꼬? 차 한 잔 하자.",
    "이 옷, 색깔이 영 안 어울리는데?",
    "그래도 열심히 해봐야 안 되겠나!",
    "아이고, 어제 술 너무 많이 묵었다.",
    "저기 사람 많은디, 조금 기다려야겠데이.",
    "학교 앞 분식집, 떡볶이 끝내준다카더라.",
    "오늘은 바람이 매마 되네예.",
    "점심 때 뭐 먹으러 갈래?",
    "요즘 일하느라 피곤 안 하나?",
    "아니, 이게 와 이리 비싼데?",
    "주말에 좀 쉬야 되는데, 약속이 또 잡혔데이.",
    "니가 할 수 있겠나?",
    "배고프다, 라면이나 하나 끓이자.",
    "어데 가도 사람 많아서 복잡하데이.",
    "내한테 거짓말하면, 금방 티 난다아이가!",
    "이런 건 처음 들어본다, 신기하데이.",
    "그 상자 안에 뭐가 들었노?",
    "니 어제 왜 안 나왔노? 다 기다렸는데.",
    "그거, 내가 벌써 해놨다.",
    "생선구이가 겁나 맛있데이, 니도 먹어볼래?",
    "다시 한번 말해봐라, 잘 못 들었다.",
    "옷이 왜 이리 얇노, 추울까 안 추울까?",
    "동생이 맨날 게임만 하고, 공부를 안 하데이.",
    "엄마가 새벽부터 밥 해놓고 갔데.",
    "거짓말 좀 작작 해라, 알겠나?",
    "와, 니는 뭐든지 잘한다. 부럽데이.",
    "내일 모레쯤 한 번 보자, 연락해라.",
    "집에 가는 길에 김밥 좀 사갈래?",
    "니 오늘 기분 좋아 보이네, 좋은 일 있나?",
    "그거 내 탓 아니다, 오해하지 마래이.",
    "요즘 사람들 다 빨리빨리 움직이데이.",
    "날이 따숩다, 봄 다 됐나 싶네예.",
    "회 먹으러 갈래? 신선한 회가 땡기네.",
    "성질 내도 뭐 달라지는 거 없데이.",
    "요새 하는 드라마, 니도 보나?",
    "학교 과제 아직도 안 했다고? 미뤄두면 혼난다아이가.",
    "밥은 묵었나, 진짜? 배고프면 큰일 나데이.",
    "니는 집에 갈 때 버스 타나, 지하철 타나?",
    "빨래가 산더미처럼 쌓였는데, 귀찮데이.",
    "동생이랑 싸웠는데, 뭐 어쩌겠노.",
    "길이 막히니까 짜증나 죽겠데이.",
    "주말에 날씨가 좋음, 바다 가고 싶다아이가.",
    "야, 니 이거 해봤나? 재밌다카더라.",
    "우리 집 가려면 쪼매 걸어야 한데이.",
    "별로 배 안 고픈데, 그냥 간식이라도 묵을까.",
    "어른들 말은 잘 들어야 한다카이.",
    "와, 이거 완전 새빨갛데이, 무섭다.",
    "친구가 서울 올라간다카더라, 좀 섭섭하데이.",
    "자전거 타고 한 바퀴 돌자, 바람 쐴 겸.",
    "전화가 왜 안 받노, 바쁜가?",
    "그렇게 해서 성공하겠나, 노력해야지.",
    "컴퓨터가 갑자기 다운돼서 정신 없데이.",
    "자꾸 떼쓰면 안 되는데, 억수로 귀찮네.",
    "니 그거 알았나? 소문이 쫙 퍼졌다카이.",
    "오늘 밤새서 공부해야 되는데, 잠이 올까 모르겠다.",
    "동생이랑 놀다 보면 시간이 훌쩍 간다아이가.",
    "과일 좀 깎아놓을까, 니도 먹을래?",
    "용돈이 바닥이라 뭐 사 먹지도 못하겠데이.",
    "알았다, 알았다, 잔소리 그만해라, 머리 아프데이."
]

# 3) DataFrame 생성: dialect만
df = pd.DataFrame({"dialect": dialects})
print(f"총 {len(df)}개의 사투리 문장을 번역합니다.\n")

# ----------------------------
# 4) 모델 추론 (배치 처리)
# ----------------------------
batch_size = 16
num_batches = math.ceil(len(df) / batch_size)

predictions = []

for i in tqdm(range(num_batches), desc="Translating", ncols=100):
    batch_df = df.iloc[i * batch_size : (i + 1) * batch_size]
    batch_dialects = batch_df["dialect"].tolist()

    inputs = tokenizer(
        batch_dialects,
        return_tensors="pt",
        max_length=64,
        truncation=True,
        padding=True
    )
    inputs = {k: v.to(device) for k, v in inputs.items()}

    with torch.no_grad():
        output_ids = model.generate(
            inputs["input_ids"],
            attention_mask=inputs["attention_mask"],
            num_beams=4,
            max_length=64,
            early_stopping=True
        )

    batch_preds = tokenizer.batch_decode(output_ids, skip_special_tokens=True)
    predictions.extend(batch_preds)

# ----------------------------
# 5) 결과 출력
# ----------------------------
print("\n=== 번역 결과 (사투리 → 모델 번역) ===\n")
for idx, dialect_text in enumerate(dialects):
    print(f"{idx+1}. dialect : {dialect_text}")
    print(f"   predict : {predictions[idx]}")
    print("-----")

print("출력이 완료되었습니다!")
